import cv2
import numpy as np
import os
from scipy.optimize import least_squares
from tomlkit import boolean
from tqdm import tqdm
import matplotlib.pyplot as plt

class Image_loader():
    def __init__(self, img_dir:str, downscale_factor:float):
        # loading the Camera intrinsic parameters K
        with open(img_dir + '\\K.txt') as f:
            # å†…å‚è½¬æ¢åˆ°numpy floatçŸ©é˜µ
            self.K = np.array(list((map(lambda x:list(map(lambda x:float(x), x.strip().split(' '))),f.read().split('\n')))))
            self.image_list = []
        # Loading the set of images
        for image in sorted(os.listdir(img_dir)):
            if image[-4:].lower() == '.jpg' or image[-5:].lower() == '.png':
                self.image_list.append(img_dir + '\\' + image)
        
        self.path = os.getcwd()
        self.factor = downscale_factor
        # å¯¹å›¾åƒåšäº†ä¸‹é‡‡æ ·ï¼Œå›¾åƒå°ºå¯¸å˜å°ï¼Œåˆ™ç„¦è·ä¹Ÿè¦æŒ‰åŒæ ·æ¯”ä¾‹å˜å°ï¼Œä¸»ç‚¹åæ ‡ä¹Ÿè¦ç¼©æ”¾
        self.downscale()

    
    def downscale(self) -> None:
        '''
        Downscales the Image intrinsic parameter acc to the downscale factor
        '''
        self.K[0, 0] /= self.factor
        self.K[1, 1] /= self.factor
        self.K[0, 2] /= self.factor
        self.K[1, 2] /= self.factor
    
    def downscale_image(self, image):
        # factor = 2 å¾ªç¯ä¸€æ¬¡ï¼Œfactor = 4 å¾ªç¯ä¸¤æ¬¡
        for _ in range(1,int(self.factor / 2) + 1):
            # æ¯æ‰§è¡Œä¸€æ¬¡ï¼Œå°±ä¼šå°†å›¾åƒçš„å®½é«˜å„ç¼©å°ä¸€åŠ
            image = cv2.pyrDown(image)
        return image

class Sfm():
    def __init__(self, img_dir:str, downscale_factor:float = 2.0) -> None:
        '''
            Initialise and Sfm object.
        '''
        self.img_obj = Image_loader(img_dir,downscale_factor)

    def triangulation(self, point_2d_1, point_2d_2, projection_matrix_1, projection_matrix_2) -> tuple:
        '''
        Triangulates 3d points from 2d vectors and projection matrices
        returns projection matrix of first camera, projection matrix of second camera, point cloud 
        '''
        # point_2d_1 ç¬¬ä¸€å¹…å›¾åƒä¸­åŒ¹é…åˆ°çš„ 2D ç‰¹å¾ç‚¹
        # point_2d_2 ç¬¬äºŒå¹…å›¾åƒä¸­åŒ¹é…åˆ°çš„åŒä¸€æ‰¹ 2D ç‰¹å¾ç‚¹ï¼Œä¸ point_2d_1 ä¸€ä¸€å¯¹åº”ã€‚
        # projection_matrix_1.T ç¬¬ä¸€å°ç›¸æœºçš„æŠ•å½±çŸ©é˜µï¼ˆ3Ã—4ï¼‰ï¼Œåœ¨ä»£ç é‡Œåšäº† .T è½¬ç½®ä¼ å…¥ã€‚
        # ç¬¬äºŒå°ç›¸æœºçš„æŠ•å½±çŸ©é˜µï¼ˆ3Ã—4ï¼‰ï¼Œä¸ç¬¬ä¸€å°ç±»ä¼¼ï¼ŒåŒæ ·åšäº†è½¬ç½®åä¼ å…¥
        # ä¸€ä¸ªå®Œæ•´çš„æŠ•å½±çŸ©é˜µPæ˜¯ (3Ã—4)ï¼Œå¯ä»¥å°† 3D ç‚¹(X,Y,Z,1)æŠ•å½±åˆ° 2D å›¾åƒä¸Šçš„(x,y,1)
        # å®ƒä¼šæ ¹æ®ä¸¤å¹…å›¾åƒé‡ŒåŒä¸€æ‰¹ç©ºé—´ç‚¹çš„æŠ•å½±åæ ‡ï¼Œä»¥åŠä¸¤å°ç›¸æœºçš„æŠ•å½±çŸ©é˜µï¼Œæ±‚è§£å‡ºè¿™äº›ç©ºé—´ç‚¹çš„é½æ¬¡åæ ‡(4Ã—N)
        # 2D(å¤šå¼ å›¾ç‰‡é€šè¿‡æŠ•å½±çŸ©é˜µ)-> 3D(é½æ¬¡åæ ‡)->éé½æ¬¡åæ ‡ï¼ˆ3Dç‚¹ï¼‰
        pt_cloud = cv2.triangulatePoints(point_2d_1, point_2d_2, projection_matrix_1.T, projection_matrix_2.T)
        # (pt_cloud / pt_cloud[3])  é½æ¬¡åæ ‡=ã€‹ï¼ˆéé½æ¬¡åæ ‡ï¼‰ä¸‰è§’åŒ–åçš„ 3D ç‚¹
        return projection_matrix_1.T, projection_matrix_2.T, (pt_cloud / pt_cloud[3])    
    
    def PnP(self, obj_point, image_point , K, dist_coeff, rot_vector, initial) ->  tuple:
        '''
        Finds an object pose from 3D-2D point correspondences using the RANSAC scheme.
        returns rotational matrix, translational matrix, image points, object points, rotational vector
        '''
        #é€šè¿‡å·²çŸ¥çš„3Dç‚¹å’Œå…¶åœ¨2Då›¾åƒä¸­çš„æŠ•å½±ç‚¹æ¥ä¼°ç®—æ‘„åƒæœºçš„å§¿æ€ï¼ˆä½ç½®å’Œæ–¹å‘ï¼‰ã€‚
        # obj_pointï¼š3D å¯¹åº”ç‚¹åæ ‡
        # image_pointï¼š2D å›¾åƒç‚¹åæ ‡ å®ƒä¸ obj_point ä¸€ä¸€å¯¹åº”

        if initial == 1:
            # (N,1,3) =ã€‹(N,3)
            obj_point = obj_point[:, 0 ,:]
            # OpenCV çš„ PnP æ¥å£ä¸€èˆ¬è¦æ±‚è¾“å…¥çš„ 2D ç‚¹æ˜¯(N,2)
            image_point = image_point.T
            # ä¸ºäº†åé¢çš„ä¸€è‡´æ€§è€Œåšçš„è½¬ç½®
            rot_vector = rot_vector.T 
        # ç”¨ RANSAC çš„æ–¹å¼è§£ PnP é—®é¢˜ï¼Œå³åœ¨ä¼—å¤š 3D-2D å¯¹åº”ç‚¹ä¸­
        # è¯†åˆ«å¹¶æ’é™¤å¼‚å¸¸å€¼ï¼Œç„¶åæ±‚è§£æœ€ä¼˜çš„æ—‹è½¬å’Œå¹³ç§»
        # rot_vector_calcï¼šæ—‹è½¬å‘é‡ï¼ˆRodrigues å½¢å¼ï¼‰
        # tran_vectorï¼šå¹³ç§»å‘é‡ (3Ã—1)
        # inlierå†…ç‚¹ç´¢å¼•(M,1) æ•°ç»„ è¡¨ç¤ºåœ¨ RANSAC è¿‡ç¨‹ä¸­è¢«è®¤ä¸ºæ˜¯â€œç¬¦åˆâ€æ¨¡å‹çš„ 3D-2D åŒ¹é…ç‚¹ç´¢å¼•ã€‚
        _, rot_vector_calc, tran_vector, inlier = cv2.solvePnPRansac(obj_point, image_point, K, dist_coeff, cv2.SOLVEPNP_ITERATIVE)
        # å¦‚æœä¼ å…¥çš„æ˜¯ 3Ã—1 çš„æ—‹è½¬å‘é‡ï¼Œå°±å¾—åˆ° 3Ã—3 çš„æ—‹è½¬çŸ©é˜µ
        # Converts a rotation matrix to a rotation vector or vice versa
        # rot_matrix æ˜¯ (3Ã—3)ï¼Œå¯è§†ä¸ºç›¸æœºå¤–å‚ä¸­çš„æ—‹è½¬éƒ¨åˆ†
        rot_matrix, _ = cv2.Rodrigues(rot_vector_calc)

        if inlier is not None:
            image_point = image_point[inlier[:, 0]]
            obj_point = obj_point[inlier[:, 0]]
            rot_vector = rot_vector[inlier[:, 0]]
        # rot_matrixï¼š(3Ã—3) çš„æ—‹è½¬çŸ©é˜µï¼Œç›¸æœºå¤–å‚çš„ Rã€‚
        # tran_vectorï¼š(3Ã—1) çš„å¹³ç§»å‘é‡ï¼Œç›¸æœºå¤–å‚çš„ tã€‚
        # image_point & obj_pointï¼šè¿‡æ»¤äº†å†…ç‚¹åçš„ä¸€è‡´ 2D-3D å¯¹åº”ç‚¹
        # rot_vectorï¼šè¿™é‡Œä¿ç•™äº†æ»¤å®Œå†…ç‚¹åçš„æ—‹è½¬å‘é‡
        return rot_matrix, tran_vector, image_point, obj_point, rot_vector
    
    #reprojection_error æ›´åƒæ˜¯ç‹¬ç«‹åœ°è®¡ç®—â€œå½“å‰ä¼°è®¡å¥½/å‡è®¾å¥½çš„å¤–å‚å’Œ 3D ç‚¹ä¸‹ï¼ŒæŠ•å½±è¯¯å·®æ˜¯å¤šå°‘â€ï¼Œç»™ä½ ä¸€ä¸ªç›´è§‚çš„æ•°å€¼åšè¯„ä¼°
    def reprojection_error(self, obj_points, image_points, transform_matrix, K, homogenity) ->tuple:
        '''
        Calculates the reprojection error ie the distance between the projected points and the actual points.
        returns total error, object points
        '''
        # æ˜¯åœ¨å·²çŸ¥3Dç‚¹ã€ç›¸æœºä½å§¿å’Œç›¸æœºå†…å‚çš„æ¡ä»¶ä¸‹ï¼Œ
        # æŠŠ3Dç‚¹é‡æ–°æŠ•å½±åˆ°å›¾åƒå¹³é¢ï¼Œå’Œå¯¹åº”çš„çœŸå®2Dè§‚æµ‹ç‚¹åšå¯¹æ¯”ï¼Œ
        # è¡¡é‡å®ƒä»¬ä¹‹é—´çš„å¹³å‡è·ç¦»ï¼ˆå³é‡æŠ•å½±è¯¯å·®ï¼‰
        rot_matrix = transform_matrix[:3, :3]
        tran_vector = transform_matrix[:3, 3]
        rot_vector, _ = cv2.Rodrigues(rot_matrix)
        # æŠŠæœ‰äº›åœ°æ–¹ä¸‰è§’åŒ–æ²¡æœ‰è½¬æ¢ä¸ºéé½æ¬¡åæ ‡çš„åæ ‡ä»é½æ¬¡åæ ‡è½¬åŒ–
        if homogenity == 1:
            obj_points = cv2.convertPointsFromHomogeneous(obj_points.T)
        # 3D => 2D
        image_points_calc, _ = cv2.projectPoints(obj_points, rot_vector, tran_vector, K, None)
        image_points_calc = np.float32(image_points_calc[:, 0, :])
        # è¿™é‡Œç¡®ä¿(N,2)
        total_error = cv2.norm(image_points_calc, np.float32(image_points.T) if homogenity == 1 else np.float32(image_points), cv2.NORM_L2)
        return total_error / len(image_points_calc), obj_points
    #å¤–éƒ¨ç”¨äº†least_squaresåå¤è°ƒç”¨ï¼Œå¯¹ x0 åšè¿­ä»£æ›´æ–°ä»¥æœ€å°åŒ–é‡æŠ•å½±è¯¯å·®ã€‚
    def optimal_reprojection_error(self, obj_points) -> np.array:
        '''
        calculates of the reprojection error during bundle adjustment
        returns error 
        '''
        # å®ƒä¼šæ ¹æ®æ‰“åŒ…åœ¨ä¸€èµ·çš„å„é¡¹ï¼ˆå¤–å‚ã€å†…å‚ã€2D ç‚¹ã€3D ç‚¹ï¼‰
        # æ¥è®¡ç®—é‡æŠ•å½±è¯¯å·®ã€‚
        # ç„¶å least_squares ç­‰ä¼˜åŒ–å™¨ä¼šåå¤è°ƒç”¨å®ƒæ¥è¿­ä»£æ›´æ–°å‚æ•°ã€‚
        transform_matrix = obj_points[0:12].reshape((3,4))
        K = obj_points[12:21].reshape((3,3))
        rest = int(len(obj_points[21:]) * 0.4)
        # 40% 2Dç‚¹
        p = obj_points[21:21 + rest].reshape((2, int(rest/2))).T
        # 60% 3Dç‚¹
        obj_points = obj_points[21 + rest:].reshape((int(len(obj_points[21 + rest:])/3), 3))
        rot_matrix = transform_matrix[:3, :3]
        tran_vector = transform_matrix[:3, 3]
        # æ—‹è½¬çŸ©é˜µ=ã€‹æ—‹è½¬å‘é‡
        rot_vector, _ = cv2.Rodrigues(rot_matrix)
        # 3D=ã€‹2D
        image_points, _ = cv2.projectPoints(obj_points, rot_vector, tran_vector, K, None)
        image_points = image_points[:, 0, :]
        # å¹³æ–¹è¯¯å·®
        error = [ (p[idx] - image_points[idx])**2 for idx in range(len(p))]
        return np.array(error).ravel()/len(p)

    def bundle_adjustment(self, _3d_point, opt, transform_matrix_new, K, r_error) -> tuple:
        '''
        Bundle adjustment for the image and object points
        returns object points, image points, transformation matrix
        '''
        #æ—¨åœ¨æœ€å°åŒ–é‡æŠ•å½±è¯¯å·®
        #ä¼˜åŒ–ï¼ˆä¿®æ­£ï¼‰ç›¸æœºå¤–å‚ã€å†…å‚ï¼Œä»¥åŠ 3D/2D ç‚¹çš„åæ ‡ã€‚
        opt_variables = np.hstack((transform_matrix_new.ravel(), K.ravel()))
        opt_variables = np.hstack((opt_variables, opt.ravel()))
        opt_variables = np.hstack((opt_variables, _3d_point.ravel()))
        # least_squaresæ˜¯ä¸€ä¸ªéçº¿æ€§æœ€å°äºŒä¹˜é—®é¢˜æ±‚è§£å™¨ã€‚
        values_corrected = least_squares(self.optimal_reprojection_error, opt_variables, gtol = r_error).x
        K = values_corrected[12:21].reshape((3,3))
        rest = int(len(values_corrected[21:]) * 0.4)
        # å‡½æ•°è¿”å› 3D ç‚¹ï¼Œ2D ç‚¹ï¼Œ(3Ã—4) ç›¸æœºå¤–å‚
        return values_corrected[21 + rest:].reshape((int(len(values_corrected[21 + rest:])/3), 3)), values_corrected[21:21 + rest].reshape((2, int(rest/2))).T, values_corrected[0:12].reshape((3,4))

    def to_ply(self, path, point_cloud, colors) -> None:
        '''
        Generates the .ply which can be used to open the point cloud
        '''
        out_points = point_cloud.reshape(-1, 3) * 200
        out_colors = colors.reshape(-1, 3)
        print(out_colors.shape, out_points.shape)
        # å½¢çŠ¶æ˜¯(N,6)ï¼Œå…¶ä¸­å‰ 3 åˆ—æ˜¯ä½ç½®ï¼Œå 3 åˆ—æ˜¯é¢œè‰²ã€‚
        verts = np.hstack([out_points, out_colors])


        mean = np.mean(verts[:, :3], axis=0)
        scaled_verts = verts[:, :3] - mean
        # è®¡ç®—æ¯ä¸ªç‚¹åˆ°è´¨å¿ƒçš„æ¬§å‡ é‡Œå¾—è·ç¦» dist
        dist = np.sqrt(scaled_verts[:, 0] ** 2 + scaled_verts[:, 1] ** 2 + scaled_verts[:, 2] ** 2)
        # å»æ‰éå¸¸ç¦»ç¾¤çš„ç‚¹
        indx = np.where(dist < np.mean(dist) + 300)
        verts = verts[indx]
        ply_header = '''ply
            format ascii 1.0
            element vertex %(vert_num)d
            property float x
            property float y
            property float z
            property uchar blue
            property uchar green
            property uchar red
            end_header
            '''
        with open(path + '\\res\\' + self.img_obj.image_list[0].split('\\')[-2] + '.ply', 'w') as f:
            f.write(ply_header % dict(vert_num=len(verts)))
            np.savetxt(f, verts, '%f %f %f %d %d %d')


    def common_points(self, image_points_1, image_points_2, image_points_3) -> tuple:
        '''
        Finds the common points between image 1 and 2 , image 2 and 3
        returns common points of image 1-2, common points of image 2-3, mask of common points 1-2 , mask for common points 2-3 
        '''
        #è¯•å›¾æ‰¾å‡ºåœ¨ image_points_1 å’Œ image_points_2 ä¸­ç›¸åŒçš„ 2D ç‚¹åæ ‡ï¼Œ
        # ç„¶åç›¸åº”åœ°åœ¨ image_points_3 åšä¸€äº›æ©ç å¤„ç†
        # å®ƒè¿”å› 4 ä¸ªå†…å®¹ï¼Œä»¥ä¾¿åç»­åœ¨ä¸‰è§’åŒ–æˆ– PnP ç­‰æ“ä½œä¸­ä½¿ç”¨ã€‚
        cm_points_1 = []
        cm_points_2 = []
        for i in range(image_points_1.shape[0]):
            # è¿‘ä¼¼è·ç¦»â€åˆ¤æ–­æ›´å¥½ ï¼Œ== å¯èƒ½ä¼šæœ‰ç²¾åº¦éšæ‚£
            a = np.where(image_points_2 == image_points_1[i, :])
            if a[0].size != 0:
                cm_points_1.append(i)
                cm_points_2.append(a[0][0])
        # å¯¹ image_points_2 å’Œ image_points_3 åšæ©ç å¹¶å‹ç¼©
        mask_array_1 = np.ma.array(image_points_2, mask=False)
        mask_array_1.mask[cm_points_2] = True
        mask_array_1 = mask_array_1.compressed()
        mask_array_1 = mask_array_1.reshape(int(mask_array_1.shape[0] / 2), 2)

        mask_array_2 = np.ma.array(image_points_3, mask=False)
        mask_array_2.mask[cm_points_2] = True
        mask_array_2 = mask_array_2.compressed()
        mask_array_2 = mask_array_2.reshape(int(mask_array_2.shape[0] / 2), 2)
        print(" Shape New Array", mask_array_1.shape, mask_array_2.shape)
        return np.array(cm_points_1), np.array(cm_points_2), mask_array_1, mask_array_2


    def find_features(self, image_0, image_1) -> tuple:
        '''
        Feature detection using the sift algorithm and KNN
        return keypoints(features) of image1 and image2
        '''
        # åˆ›å»º SIFT æ£€æµ‹å™¨
        sift = cv2.xfeatures2d.SIFT_create()
        key_points_0, desc_0 = sift.detectAndCompute(cv2.cvtColor(image_0, cv2.COLOR_BGR2GRAY), None)
        key_points_1, desc_1 = sift.detectAndCompute(cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY), None)
        # Brute-Force Matcherï¼Œæš´åŠ›åŒ¹é…å™¨ï¼Œä¼šè®¡ç®—ä¸¤ä¸ªæè¿°å­é›†åˆä¹‹é—´çš„è·ç¦»
        bf = cv2.BFMatcher()
        # å¯¹ desc_0 ä¸­æ¯ä¸ªæè¿°å­ï¼Œåœ¨ desc_1 ä¸­æ‰¾åˆ°è·ç¦»æœ€è¿‘å’Œæ¬¡è¿‘çš„ä¸¤ä¸ªæè¿°å­
        matches = bf.knnMatch(desc_0, desc_1, k=2)
        feature = []
        #æœ€è¿‘åŒ¹é…å’Œæ¬¡è¿‘åŒ¹é…å·®ä¸å¤šå¯èƒ½æ˜¯æ‚è´¨ï¼Œ ä¸¢å¼ƒï¼Œéœ€è¦m.distance æ˜æ˜¾å°äºæ¬¡è¿‘åŒ¹é… n.distance
        for m, n in matches:
            if m.distance < 0.70 * n.distance:
                feature.append(m)
        # è¾“å…¥ä¸¤å¹…å›¾ã€‚è¾“å‡ºè¿”å›ä¸¤ä¸ª(N,2) å½¢çŠ¶çš„ NumPy æ•°ç»„ï¼Œè¡¨ç¤ºä¸¤å¹…å›¾ä¸­äº’ç›¸åŒ¹é…çš„ç‰¹å¾ç‚¹åæ ‡
        return np.float32([key_points_0[m.queryIdx].pt for m in feature]), np.float32([key_points_1[m.trainIdx].pt for m in feature])

    def __call__(self, enable_bundle_adjustment:boolean=False):
        cv2.namedWindow('image', cv2.WINDOW_NORMAL)
        pose_array = self.img_obj.K.ravel()
        transform_matrix_0 = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0]])
        transform_matrix_1 = np.empty((3, 4))
        # æŠ•å½±çŸ©é˜µ
        pose_0 = np.matmul(self.img_obj.K, transform_matrix_0)
        pose_1 = np.empty((3, 4)) 
        total_points = np.zeros((1, 3))
        total_colors = np.zeros((1, 3))

        image_0 = self.img_obj.downscale_image(cv2.imread(self.img_obj.image_list[0]))
        image_1 = self.img_obj.downscale_image(cv2.imread(self.img_obj.image_list[1]))

        feature_0, feature_1 = self.find_features(image_0, image_1)

        # Essential matrix
        #å¯ä»¥åœ¨ç»™å®šå†…å‚ä¸åŒ¹é…ç‚¹å¯¹çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡ RANSAC æˆ–å…¶ä»–æ–¹æ³•ç¨³å¥åœ°ä¼°è®¡å‡ºè¿™ä¸ªæœ¬è´¨çŸ©é˜µ ğ¸
        # å¹¶è¿”å›ä¸€ä¸ªå†…ç‚¹æ©ç ä»¥åŒºåˆ†å¤–ç‚¹/å†…ç‚¹ã€‚
        # è¿™é‡Œæœ¬è´¨çŸ©é˜µæ ¹æ®Kçš„å¹³ç§»å’Œæ—‹è½¬
        essential_matrix, em_mask = cv2.findEssentialMat(feature_0, feature_1, self.img_obj.K, method=cv2.RANSAC, prob=0.999, threshold=0.4, mask=None)
        feature_0 = feature_0[em_mask.ravel() == 1]
        feature_1 = feature_1[em_mask.ravel() == 1]

        #å­˜åœ¨ä¸€å®šçš„**â€œå°ºåº¦ä¸ç¡®å®šâ€å’Œâ€œå¹³ç§»æ–¹å‘æ­§ä¹‰â€**(æœ€å¤šæœ‰å››ç§å¯èƒ½è§£)ã€‚
        # å› æ­¤ï¼ŒrecoverPose çš„ç›®çš„å°±æ˜¯ä» E ä¸­é€‰å‡ºä¸€ä¸ªâ€œåˆç†çš„ R,tâ€
        _, rot_matrix, tran_matrix, em_mask = cv2.recoverPose(essential_matrix, feature_0, feature_1, self.img_obj.K)
        feature_0 = feature_0[em_mask.ravel() > 0]
        feature_1 = feature_1[em_mask.ravel() > 0]       
        # æˆ‘ä»¬è¦å°†ä¸Šä¸€å¸§çš„ä½å§¿ä¸è¿™ä¸€æ¬¡çš„ç›¸å¯¹è¿åŠ¨â€œç´¯ä¹˜â€èµ·æ¥
        # è‹¥ä¸Šä¸€å¸§å§¿æ€æ˜¯ {R0,t0}ï¼Œæœ¬æ¬¡ç›¸å¯¹è¿åŠ¨æ˜¯ {R,t}
        # R1â€‹=RR0
        transform_matrix_1[:3, :3] = np.matmul(rot_matrix, transform_matrix_0[:3, :3])
        #â€‹ t1â€‹=t0â€‹+R0Tâ€‹t
        transform_matrix_1[:3, 3] = transform_matrix_0[:3, 3] + np.matmul(transform_matrix_0[:3, :3], tran_matrix.ravel())
        # ç”ŸæˆæŠ•å½±çŸ©é˜µ P=K[Râˆ£t]
        pose_1 = np.matmul(self.img_obj.K, transform_matrix_1)
        # æŠ•å½±çŸ©é˜µä¸‰è§’åŒ– å¾—åˆ°ä¸€æ‰¹ 3D ç‚¹ points_3d
        feature_0, feature_1, points_3d = self.triangulation(pose_0, pose_1, feature_0, feature_1)
        # å†æŠŠè¿™äº› 3D ç‚¹æŠ•å½±å›æ¥ï¼Œæ±‚å’ŒçœŸå®æµ‹é‡çš„ feature_1 åšæ¯”è¾ƒï¼Œå¾—åˆ°é‡æŠ•å½±è¯¯å·® error
        error, points_3d = self.reprojection_error(points_3d, feature_1, transform_matrix_1, self.img_obj.K, homogenity = 1)
        #ideally error < 1
        print("REPROJECTION ERROR: ", error)
        # å†ç”¨ PnP åšè¿›ä¸€æ­¥çš„ä½å§¿/å¤–ç‚¹ç­›é€‰ä¿®æ­£ï¼Œè·å¾—æ›´å¯é çš„å¤–å‚æˆ–ç‚¹äº‘ã€‚
        # é€šè¿‡å·²çŸ¥çš„3Dç‚¹å’Œå…¶åœ¨2Då›¾åƒä¸­çš„æŠ•å½±ç‚¹æ¥ä¼°ç®—æ‘„åƒæœºçš„å§¿æ€ï¼ˆä½ç½®å’Œæ–¹å‘ï¼‰
        # è¿™é‡Œåªæ˜¯è·å¾—ä¸€äº›ç¨³å®šçš„3Dç‚¹
        _, _, feature_1, points_3d, _ = self.PnP(points_3d, feature_1, self.img_obj.K, np.zeros((5, 1), dtype=np.float32), feature_0, initial=1)

        total_images = len(self.img_obj.image_list) - 2 
        pose_array = np.hstack((np.hstack((pose_array, pose_0.ravel())), pose_1.ravel()))

        threshold = 0.5
        for i in tqdm(range(total_images)):
            image_2 = self.img_obj.downscale_image(cv2.imread(self.img_obj.image_list[i + 2]))
            features_cur, features_2 = self.find_features(image_1, image_2)

            if i != 0:
                feature_0, feature_1, points_3d = self.triangulation(pose_0, pose_1, feature_0, feature_1)
                feature_1 = feature_1.T
                points_3d = cv2.convertPointsFromHomogeneous(points_3d.T)
                points_3d = points_3d[:, 0, :]
            

            cm_points_0, cm_points_1, cm_mask_0, cm_mask_1 = self.common_points(feature_1, features_cur, features_2)
            cm_points_2 = features_2[cm_points_1]
            cm_points_cur = features_cur[cm_points_1]

            rot_matrix, tran_matrix, cm_points_2, points_3d, cm_points_cur = self.PnP(points_3d[cm_points_0], cm_points_2, self.img_obj.K, np.zeros((5, 1), dtype=np.float32), cm_points_cur, initial = 0)
            transform_matrix_1 = np.hstack((rot_matrix, tran_matrix))
            pose_2 = np.matmul(self.img_obj.K, transform_matrix_1)
            # è®¡ç®—é‡æŠ•å½±è¯¯å·®å¹¶ä¸‰è§’åŒ– 3D ç‚¹å’Œ 2D ç‚¹åšæŠ•å½±æ¯”å¯¹ï¼Œæ‰“å°è¯¯å·®
            error, points_3d = self.reprojection_error(points_3d, cm_points_2, transform_matrix_1, self.img_obj.K, homogenity = 0)
        
            # è¿˜ç”¨ pose_1, pose_2 å¯¹ cm_mask_0, cm_mask_1 å†åšä¸€æ¬¡ä¸‰è§’åŒ–ï¼Œä»¥å¼•å…¥æ›´å¤š 3D ç‚¹ã€‚
            cm_mask_0, cm_mask_1, points_3d = self.triangulation(pose_1, pose_2, cm_mask_0, cm_mask_1)
            error, points_3d = self.reprojection_error(points_3d, cm_mask_1, transform_matrix_1, self.img_obj.K, homogenity = 1)
            print("Reprojection Error: ", error)
            pose_array = np.hstack((pose_array, pose_2.ravel()))
            # takes a long time to run
            if enable_bundle_adjustment:
                points_3d, cm_mask_1, transform_matrix_1 = self.bundle_adjustment(points_3d, cm_mask_1, transform_matrix_1, self.img_obj.K, threshold)
                pose_2 = np.matmul(self.img_obj.K, transform_matrix_1)
                error, points_3d = self.reprojection_error(points_3d, cm_mask_1, transform_matrix_1, self.img_obj.K, homogenity = 0)
                print("Bundle Adjusted error: ",error)
                total_points = np.vstack((total_points, points_3d))
                points_left = np.array(cm_mask_1, dtype=np.int32)
                color_vector = np.array([image_2[l[1], l[0]] for l in points_left])
                total_colors = np.vstack((total_colors, color_vector))
            else:
                total_points = np.vstack((total_points, points_3d[:, 0, :]))
                points_left = np.array(cm_mask_1, dtype=np.int32)
                color_vector = np.array([image_2[l[1], l[0]] for l in points_left.T])
                total_colors = np.vstack((total_colors, color_vector)) 
   


            transform_matrix_0 = np.copy(transform_matrix_1)
            pose_0 = np.copy(pose_1)
            plt.scatter(i, error)
            plt.pause(0.05)

            image_0 = np.copy(image_1)
            image_1 = np.copy(image_2)
            feature_0 = np.copy(features_cur)
            feature_1 = np.copy(features_2)
            pose_1 = np.copy(pose_2)
            cv2.imshow(self.img_obj.image_list[0].split('\\')[-2], image_2)
            if cv2.waitKey(1) & 0xff == ord('q'):
                break
        cv2.destroyAllWindows()

        print("Printing to .ply file")
        print(total_points.shape, total_colors.shape)
        self.to_ply(self.img_obj.path, total_points, total_colors)
        print("Completed Exiting ...")
        np.savetxt(self.img_obj.path + '\\res\\' + self.img_obj.image_list[0].split('\\')[-2]+'_pose_array.csv', pose_array, delimiter = '\n')

if __name__ == '__main__':
    sfm = Sfm("Datasets\\entry-P10")
    sfm()

